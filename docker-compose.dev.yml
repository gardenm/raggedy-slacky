services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "3001:3000"
      - "9229:9229" # for debugging
    env_file:
      - .env.docker-dev
    environment:
      - NODE_ENV=development
      - TS_NODE_TRANSPILE_ONLY=true  # Skip type checking
    depends_on:
      - postgres
      - chroma
      - ollama
    volumes:
      - ./src:/app/src
      - ./test:/app/test
      - ./migrations:/app/migrations
      - ./entities:/app/entities
      - ./data/slack-archive:/app/data/slack-archive:ro
      # Don't mount node_modules from host
    restart: unless-stopped
    command: sh -c "node test-server.js"
    networks:
      - app-network
      
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_API_URL=http://backend:3000/api
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - app-network

  postgres:
    image: postgres:16
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=raggedy-slacky
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - app-network

  chroma:
    image: chromadb/chroma:latest
    ports:
      - "8000:8000"
    volumes:
      - chroma-data:/chroma/chroma
    restart: unless-stopped
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    networks:
      - app-network
    # Ensure the llama3 model is downloaded on startup
    command: >
      sh -c "ollama serve &
             until ollama list 2>/dev/null; do
               echo 'Waiting for Ollama to start...'
               sleep 2
             done &&
             if ! ollama list | grep -q 'llama3'; then
               echo 'Pulling llama3 model...'
               ollama pull llama3
             fi &&
             tail -f /dev/null"

networks:
  app-network:
    driver: bridge

volumes:
  postgres-data:
  chroma-data:
  ollama-data: